import requests
from bs4 import BeautifulSoup
import json
import time
from cleaning import *

BASE_URL = "https://www.cake.me"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; StudentBot/1.0; +https://ncu.edu.tw)"
}

jobs = []

# ğŸ‘‡ è¨­å®šè¦æŠ“å–å¹¾é è·ç¼º
for page in range(1, 6):  # æŠ“å–ç¬¬1ï½5é 
    print(f"ğŸ“„ æ­£åœ¨æ“·å–ç¬¬ {page} é è³‡æ–™...")
    list_url = f"{BASE_URL}/jobs?order=latest&page={page}"
    
    response = requests.get(list_url, headers=HEADERS)
    soup = BeautifulSoup(response.text, "html.parser")
    job_cards = soup.select("div.JobSearchItem_container__oKoBL")

    for card in job_cards:
        try:
            title_tag = card.select_one("a[class^='JobSearchItem_jobTitle__']")
            company_tag = card.select_one("a[class^='JobSearchItem_companyName__']")
            location_tags = card.select("a[class^='JobSearchItem_featureSegmentLink__']")

            job_url = BASE_URL + title_tag["href"] if title_tag else ""
            requirements = ""

            # ğŸ‘‡ çˆ¬å–è·ç¼ºè©³ç´°é é¢
            if job_url:
                detail_resp = requests.get(job_url, headers=HEADERS)
                detail_soup = BeautifulSoup(detail_resp.text, "html.parser")

                section_blocks = detail_soup.select("div.ContentSection_contentSection__ELRlG")
                for section in section_blocks:
                    h3 = section.select_one("h3.ContentSection_title__fcZYs")
                    if h3 and "è·å‹™éœ€æ±‚" in h3.text:
                        content_div = section.select_one("div.ContentSection_content__e3ios")
                        if content_div:
                            requirements = content_div.get_text(separator="\n", strip=True)
                        break

            job = {
                "title": clean_text(title_tag.text) if title_tag else "",
                "url": job_url,
                "company": clean_text(company_tag.text) if company_tag else "",
                "location": normalize_list([tag.text for tag in location_tags]),
                "requirements": clean_html(str(content_div)) if content_div else ""
            }

            jobs.append(job)
            time.sleep(1)  # å»¶é²è«‹æ±‚ï¼Œé¿å…è¢«å°é–

        except Exception as e:
            print("âŒ æ“·å–å¤±æ•—ï¼š", e)

# å„²å­˜æˆ JSON æª”æ¡ˆ
with open("cake_jobs_pages.json", "w", encoding="utf-8") as f:
    json.dump(jobs, f, ensure_ascii=False, indent=2)

print(f"âœ… å…±æ“·å– {len(jobs)} ç­†è·ç¼ºè³‡æ–™ï¼Œå„²å­˜è‡³ cake_jobs_pages.json")

import csv

# å„²å­˜æˆ CSV æª”æ¡ˆ
with open("cake_jobs_pages.csv", "w", encoding="utf-8", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=["title", "url", "company", "location", "requirements"])
    writer.writeheader()

    for job in jobs:
        writer.writerow({
            "title": job["title"],
            "url": job["url"],
            "company": job["company"],
            "location": "ã€".join(job["location"]),  # å°‡ list è½‰ç‚ºæ–‡å­—ï¼Œé€—è™Ÿæˆ–é “è™Ÿåˆ†éš”
            "requirements": job["requirements"].replace("\n", " ")  # æ¸…ç†æ›è¡Œç¬¦
        })

print("âœ… å·²è¼¸å‡ºç‚º cake_jobs_pages.csv")
